================================================================================
OFFLINE CHATBOT - STEP-BY-STEP SETUP GUIDE
================================================================================

This guide will help you set up and run the Offline Pharmaceutical Chatbot.
The chatbot uses a fine-tuned LLaMA 3.2-3B model for answering pharmaceutical 
questions about lot numbers, batch records, etc.

================================================================================
PREREQUISITES
================================================================================

1. Operating System: Windows 10/11, Linux, or macOS
2. Python: Version 3.8 or higher
3. RAM: At least 8GB (16GB recommended)
4. Disk Space: At least 15GB free space
5. Internet Connection: Required for initial setup only

================================================================================
STEP 1: VERIFY PYTHON INSTALLATION
================================================================================

Open your terminal/command prompt and run:
    python --version

You should see Python 3.8 or higher. If not, download and install Python from:
    https://www.python.org/downloads/

================================================================================
STEP 2: INSTALL DEPENDENCIES
================================================================================

Navigate to the project directory:
    cd "C:\Users\ITSOLI\Downloads\offline chatbot"

Install required Python packages:
    pip install -r requirements.txt

Note for Windows Users:
- If you encounter errors with 'bitsandbytes', this is normal on Windows
- The chatbot will run on CPU mode without bitsandbytes (slightly slower but functional)

================================================================================
STEP 3: SET UP HUGGING FACE ACCESS (FIRST TIME ONLY)
================================================================================

The project uses LLaMA 3.2-3B from Meta, which requires Hugging Face authentication:

1. Create a Hugging Face account at: https://huggingface.co/join

2. Request access to LLaMA models:
   - Visit: https://huggingface.co/meta-llama/Llama-3.2-3B
   - Click "Request Access" and accept the terms

3. Generate an access token:
   - Go to: https://huggingface.co/settings/tokens
   - Click "New token"
   - Give it a name (e.g., "llama-access")
   - Select "Read" permissions
   - Copy the token

4. Login to Hugging Face from terminal:
    pip install huggingface-hub
    huggingface-cli login

   Paste your token when prompted.

================================================================================
STEP 4: RUN THE CHATBOT
================================================================================

Once dependencies are installed and HuggingFace is set up, run:

    python chat.py

Expected behavior:
- First run will download the base LLaMA model (~6GB) - this takes 10-30 minutes
- The model will then load into memory (~60-90 seconds)
- You'll see "PHARMACEUTICAL LOT ASSISTANT" interface
- Type your questions and press Enter
- Type 'quit', 'exit', or 'q' to stop the chatbot

Example questions you can ask:
- "What is lot number L456?"
- "Show me batch record for lot L123"
- "When was lot L789 manufactured?"

================================================================================
STEP 5: VERIFY IT'S WORKING
================================================================================

After running chat.py, you should see:
    ============================================================
    OFFLINE CHATBOT - Interactive Chat
    ============================================================
    
    [*] Loading model (this takes about 60-90 seconds)...
    [OK] Model loaded successfully!
    
    ============================================================
    PHARMACEUTICAL LOT ASSISTANT
    Ask questions about lot numbers, batch records, etc.
    Type 'quit' or 'exit' to stop
    ============================================================
    
    You:

If you see this, the chatbot is ready! Type a question and press Enter.

================================================================================
TROUBLESHOOTING
================================================================================

Problem: "No module named 'transformers'"
Solution: Run: pip install -r requirements.txt

Problem: "Access denied" when downloading LLaMA model
Solution: Complete Step 3 (HuggingFace authentication)

Problem: "Out of memory" error
Solution: Close other applications to free up RAM

Problem: Chat responses are very slow
Solution: This is normal on CPU. The model generates ~5-10 tokens per second.

Problem: "Adapter not found" warning
Solution: This is okay - it means you're using the pre-trained fine-tuned adapter
          in the llama3b-finetuned folder. The chatbot will still work.

Problem: On Windows, bitsandbytes installation fails
Solution: This is expected. The chatbot will automatically run in CPU mode.

================================================================================
OPTIONAL: RE-TRAINING THE MODEL
================================================================================

If you want to re-train the model with your own data:

1. Prepare your training data in JSONL format (see data/train_comprehensive.jsonl)

2. Run the fine-tuning script:
    python finetune_comprehensive.py

   Optional arguments:
    --dataset_path data/your_data.jsonl
    --num_train_epochs 3
    --output_dir ./your-model-name

Note: Fine-tuning takes several hours on CPU (faster with GPU)

================================================================================
QUICK START SUMMARY
================================================================================

For users who have already set up everything before:

1. Open terminal in project folder
2. Run: python chat.py
3. Wait ~60-90 seconds for model to load
4. Start chatting!

================================================================================
SYSTEM REQUIREMENTS SUMMARY
================================================================================

Minimum:
- CPU: Any modern processor (Intel i5/AMD Ryzen 5 or better)
- RAM: 8GB
- Storage: 15GB free
- OS: Windows 10/11, Linux, macOS

Recommended:
- CPU: Intel i7/AMD Ryzen 7 or better
- RAM: 16GB
- GPU: NVIDIA GPU with 8GB+ VRAM (for faster inference)
- Storage: 20GB+ free

================================================================================
ADDITIONAL NOTES
================================================================================

- The chatbot runs completely offline after initial setup
- All models and data are stored locally
- No internet connection needed after downloading the base model
- The fine-tuned adapter is already included in llama3b-finetuned folder
- You can use the chatbot immediately without re-training

================================================================================
SUPPORT AND DOCUMENTATION
================================================================================

For more information about the components:
- LLaMA Model: https://ai.meta.com/llama/
- Transformers: https://huggingface.co/docs/transformers/
- LoRA/PEFT: https://huggingface.co/docs/peft/

================================================================================
END OF GUIDE
================================================================================

